# -*- coding: utf-8 -*-
"""case_study.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IF1OsFy25jLVmut03kvpKLHPAxnL2irV

#  **What is the Problem Statement ?**
Using data analysis and create a predictive
model to identify what characteristics make a physician either cost-efficient or inefficient in treating patients

# **Assumptions and Goals**##
Due to ver less time , I have not writeen my assumptions in this case study and in the last section my goals was to create models that solve the business problem. How acuually model can predict and help business
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import seaborn as sns

"""# **Exploratory Data Analysis**"""

data=pd.read_csv("/content/l2_data.csv")
print(data)

#print list of columns
column_names = data.columns.tolist()
print(column_names)
print(f"Number of rows: {len(data)}")
print(f"Number of columns: {len(data.columns)}")


#print statistics of Entire data
summary_stats = data.describe()

"""# **Problem1**"""

import pandas as pd
import matplotlib.pyplot as plt

# Assuming 'filtered_data' contains the previously filtered dataset

# Extracting efficiency scores for the histogram
efficiency_scores = filtered_data['physician_efficiency']

# Creating a histogram
plt.figure(figsize=(8, 6))
plt.hist(efficiency_scores, bins=20, color='skyblue', edgecolor='black')
plt.xlabel('Efficiency Scores')
plt.ylabel('Frequency')
plt.title('Distribution of Efficiency Scores among Physicians')
plt.grid(True)
plt.tight_layout()

# Show the plot
plt.show()

import pandas as pd

# Load the dataset
data = pd.read_csv('/content/l2_data.csv')

# Filter the data for physicians who:
# - Attended an “UNKNOWN” medical school
# - Have a working specialty of “Internal Medicine”
# - Have between 200 and 400 Medicare patients
filtered_data = data[(data['physician_med_school'] == 'UNKNOWN') &
                     (data['physician_working_specialty'] == 'Internal Medicine') &
                     (data['num_medicare_patients'] >= 200) &
                     (data['num_medicare_patients'] <= 400)]

# Find the physician with the lowest efficiency score
most_efficient_physician = filtered_data[filtered_data['physician_efficiency'] == filtered_data['physician_efficiency'].min()]

# Extract the physician ID
most_efficient_physician_id = most_efficient_physician['physician_id'].iloc[0]

# Print the result
print(f"The ID of the most efficient physician is: {most_efficient_physician_id}")

"""# **Problem2**"""

import pandas as pd
import matplotlib.pyplot as plt

# Assuming 'data' is the DataFrame loaded from the CSV file

# Filter the data
filtered_data = data[(data['physician_working_specialty'] == 'Family Practice') &
                     (data['metro_area'] == 'Chicago')]

# Calculate the count of physicians for each graduation year
graduation_year_counts = filtered_data['physician_graduation_year'].value_counts().sort_index()

# Calculate the average graduation year
average_graduation_year = filtered_data['physician_graduation_year'].mean()

# Create a bar chart for physician graduation years
plt.figure(figsize=(10, 6))
graduation_year_counts.plot(kind='bar', color='skyblue', edgecolor='black')
plt.axhline(average_graduation_year, color='red', linestyle='dashed', linewidth=1, label=f'Avg: {average_graduation_year:.2f}')
plt.xlabel('Graduation Year')
plt.ylabel('Count')
plt.title('Count of Physicians by Graduation Year')
plt.legend()
plt.grid(axis='y')
plt.tight_layout()

# Show the plot
plt.show()

import pandas as pd

# Load the dataset
data = pd.read_csv('/content/l2_data.csv')

# Filter the data for physicians who:
# - Have a "Family Practice" working specialty
# - Are located in the Chicago metro area
filtered_data = data[(data['physician_working_specialty'] == 'Family Practice') &
                     (data['metro_area'] == 'Chicago')]

# Calculate the average graduation year
average_graduation_year = filtered_data['physician_graduation_year'].mean()

# Print the result
print(f"The average graduation year of physicians is: {average_graduation_year}")

"""# **Problem3**

"""

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('/content/l2_data.csv')  # Replace with your actual file path

# Filter data for "Family Practice" and "Oncology"
family_practice_data = data[data['physician_working_specialty'] == 'Family Practice']
oncology_data = data[data['physician_working_specialty'] == 'Oncology']

# Creating the visualization
plt.figure(figsize=(10, 6))

# Histogram for "Family Practice"
plt.hist(family_practice_data['physician_efficiency'], color='blue', alpha=0.7, label='Family Practice', bins=20)

# Histogram for "Oncology"
plt.hist(oncology_data['physician_efficiency'], color='red', alpha=0.7, label='Oncology', bins=20)

# Adding title and labels
plt.title('Distribution of Physician Efficiency for Family Practice and Oncology')
plt.xlabel('Physician Efficiency')
plt.ylabel('Frequency')
plt.legend()

# Display the plot
plt.show()

"""# **Problem4**
 When we look at the chart showing 'medicare_engineered_1' and 'medicare_engineered_2', it's hard to see a clear pattern. The points are all over the place, which means these two things don't seem to move together in a specific way.
 Should We Use These in a Prediction?:

* Neither of Them: If neither of these things helps to predict what we want to know, then we shouldn't use either of them.

* Just One of Them: If one of these things helps to make a good prediction but the other doesn't, then we should only use the helpful one.

* Both of Them: If both are helpful for making predictions, or if they work together in a special way to help us predict, then we should use both.

"""

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('/content/l2_data.csv')  # Replace with your actual file path

# Creating the scatter plot
plt.figure(figsize=(8, 6))
plt.scatter(data['medicare_engineered_1'], data['medicare_engineered_2'], color='blue', alpha=0.5)

# Adding title and labels
plt.title('Scatter Plot of medicare_engineered_1 vs medicare_engineered_2')
plt.xlabel('medicare_engineered_1')
plt.ylabel('medicare_engineered_2')

# Display the plot
plt.show()

"""# **problem 5**
In the mail , I sepereately attached my Training dataset and Testing dataset and I dropped this columns and Implemented the Linear regression as my 1st Machine learning model and KNN As my 2nd machine learning model  and According to the question , I carefully split the data into a training set with 75% of the data and a test set with 25% of the data
"""

train_data=pd.read_excel("/content/train_data.xlsx")
print(train_data)

test_data=pd.read_excel("/content/test_data.xlsx")
print(test_data)

"""# **Question 6**

 Build a linear regression model with physician_efficiency as the target (i.e.
dependent) variable.

Before Implementing any dataset , I always follow these steps like Select only the numeric columns not categorical variables and later I try to  Separate the features and the target variable. and By using the traing dataset , I actually Train a Linear Regression model with the training data. and Later Our model will Predict values on the test data. so that in the final step we can Evaluate the model using Mean Squared Error and R² Score.
"""

# Import necessary libraries
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Load training and testing datasets from Excel files
train_data = pd.read_excel('/content/train_data.xlsx')
test_data = pd.read_excel('/content/test_data.xlsx')

# Select only numeric columns from datasets
numeric_train_data = train_data.select_dtypes(include=['number'])
numeric_test_data = test_data.select_dtypes(include=['number'])

# Prepare the Data: Separate features (X) and the target variable (y)
X_train = numeric_train_data.drop('physician_efficiency', axis=1)
y_train = numeric_train_data['physician_efficiency']
X_test = numeric_test_data.drop('physician_efficiency', axis=1)
y_test = numeric_test_data['physician_efficiency']

# Create a Linear Regression model and train it with training data
model = LinearRegression()
model.fit(X_train, y_train)

# Use the model to make predictions on the test dataset
y_pred_test = model.predict(X_test)

# Evaluate the model's performance using Mean Squared Error and R² Score
mse_test = mean_squared_error(y_test, y_pred_test)
r2_test = r2_score(y_test, y_pred_test)

# Print the evaluation metrics
print(f"Mean Squared Error: {mse_test}")
print(f"R² Score: {r2_test}")

"""For the Question 6 , After Implementing the Machine learning Linear model on both training dataset and testing dataset , I achived **Mean Squared Error: 0.02612282237335733** and **R² Score: 0.811633868680894** So to acutally tell what is MSE is a measure of the average squared difference between the observed actual outcomes and the outcomes predicted by the model. Lower values are better. and In a Linear model we also calulated the R² Score is a statistical measure of how close the data are to the fitted regression line. It is the proportion of the variance in the dependent variable that is predictable from the independent variables. Higher values (closer to 1) are better."""

import matplotlib.pyplot as plt

# Assuming mse_test and r2_test are your calculated metrics
mse_test = 0.026  # example value
r2_test = 0.812   # example value

# Create a bar plot
plt.figure(figsize=(10, 6))
metrics = ['Mean Squared Error', 'R² Score']
values = [mse_test, r2_test]

plt.bar(metrics, values, color=['blue', 'green'])

# Adding details to the plot
plt.title('Comparison of Regression Metrics')
plt.ylabel('Value')
plt.ylim(0, 1) # Adjust as necessary

for i, v in enumerate(values):
    plt.text(i, v + 0.02, str(v), ha='center', va='bottom')

# Show plot
plt.show()

"""# **Question 7 **

I've Used the same training dataset and testing dataset and  Build a predictive model of your choice (not a linear model) with the same data
from question 5, and the same train-test split, and same target variable as in question #6. If you

"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd

# Load the training and testing datasets
train_data_path = '/content/train_data.xlsx'
test_data_path = '/content/test_data.xlsx'

train_data = pd.read_excel(train_data_path)
test_data = pd.read_excel(test_data_path)

# Preparing the data
X_train = train_data.drop('physician_efficiency', axis=1).select_dtypes(include=['number'])
y_train = train_data['physician_efficiency']
X_test = test_data.drop('physician_efficiency', axis=1).select_dtypes(include=['number'])
y_test = test_data['physician_efficiency']

# Building the KNN model
knn_model = KNeighborsRegressor(n_neighbors=5)
knn_model.fit(X_train, y_train)

y_pred_test_knn = knn_model.predict(X_test)

mse_knn = mean_squared_error(y_test, y_pred_test_knn)
r2_knn = r2_score(y_test, y_pred_test_knn)

print("KNN Mean Squared Error (MSE):", mse_knn)
print("KNN R-squared (R2) Score:", r2_knn)

import matplotlib.pyplot as plt

mse_knn = 0.0003413088155759871
r2_knn = 0.9975388945246313

plt.figure(figsize=(10, 6))
metrics = ['Mean Squared Error', 'R² Score']
values = [mse_knn, r2_knn]

plt.bar(metrics, values, color=['red', 'blue'])

plt.title('KNN Regression Metrics')
plt.ylabel('Value')
plt.ylim(0, 1)

for i, v in enumerate(values):
    plt.text(i, v + 0.02, str(v), ha='center', va='bottom')

# Show plot
plt.show()

# Load the training and testing datasets
train_data_path = '/content/train_data.xlsx'
test_data_path = '/content/test_data.xlsx'

train_data = pd.read_excel(train_data_path)
test_data = pd.read_excel(test_data_path)

# Preparing the data
X_train = train_data.drop('physician_efficiency', axis=1).select_dtypes(include=['number'])
y_train = train_data['physician_efficiency']
X_test = test_data.drop('physician_efficiency', axis=1).select_dtypes(include=['number'])
y_test = test_data['physician_efficiency']

# Building the KNN model
knn_model = KNeighborsRegressor(n_neighbors=5)
knn_model.fit(X_train, y_train)

# Making predictions on the test set
y_pred_test_knn = knn_model.predict(X_test)

mse_knn = mean_squared_error(y_test, y_pred_test_knn)
r2_knn = r2_score(y_test, y_pred_test_knn)

# Data Visualizations using matplotlib
plt.figure(figsize=(12, 6))

# Actual vs Predicted scatter plot
plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred_test_knn, c='blue', alpha=0.6, label='Actual', marker='o', edgecolors='black')
plt.scatter(y_test, y_test, c='red', alpha=0.4, label='Predicted', marker='o', edgecolors='black')
plt.title('Actual vs. Predicted Values')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.legend()

# Residuals plot
plt.subplot(1, 2, 2)
residuals = y_test - y_pred_test_knn
plt.scatter(y_pred_test_knn, residuals, c='green', alpha=0.6)
plt.title('Residuals Plot')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')

plt.tight_layout()
plt.show()

# accuracy and performance metrics
print("KNN Mean Squared Error (MSE):", mse_knn)
print("KNN R-squared (R2) Score:", r2_knn)

#  to identify outliers
def find_outliers(residuals, threshold=2):
    mean_res = np.mean(residuals)
    std_res = np.std(residuals)
    outliers = np.abs((residuals - mean_res) / std_res) > threshold
    return outliers

# Calculate outliers in residuals
outliers = find_outliers(residuals)

# Scatter plot
plt.scatter(y_pred_test_knn[~outliers], residuals[~outliers], c='green', alpha=0.6, label='Inliers')
plt.scatter(y_pred_test_knn[outliers], residuals[outliers], c='red', alpha=0.6, label='Outliers')
plt.title('Residuals Plot with Outliers Highlighted')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.legend()


plt.show()

"""# **Question 8**
I recommend using the K-Nearest Neighbors (KNN) model for your predictive task. Here's why: KNN performs better at making predictions compared to Linear Regression. It's like having a friend who can give you answers that are closer to the correct ones. Additionally, KNN has a special ability to spot unusual data points, kind of like finding outliers in a group of friends. This helps you identify any strange or unexpected things in your data. So, KNN not only gives better predictions but also helps you understand your data better.
 From the Below Grpahs we can clearly observe that , Red plots are the outliers which are outside of the Metro city (My Assumption)

 * So My First Model Linear Model
Mean Squared Error: 0.02612282237335733
R² Score: 0.811633868680894
 * So My Second Model KNN

 KNN Mean Squared Error (MSE): 0.0003413088155759871
 KNN R-squared (R2) Score: 0.9975388945246313
 But according to me Iprefer using the KNN Model ,
 and additionally ,  KNN can capture complex relationships between features without assuming linearity, making it more suitable for datasets where the relationship between variables isn't strictly linear. Unlike linear models, KNN doesn't make assumptions about the underlying data distribution and KNN is conceptually simpler and easier to implement, especially for small datasets

# **Question 9**
How Well my model can be helpful in Solving the Business case Problem ?

 So, The KNN can predict patient outcomes based on medical data, aiding in treatment decisions and resource allocation.
 I may better get good accuracy , like better Mean squared error , but their may be bad outliers and null values.
 * The model can be used to analyze the performance of physicians. Understanding efficiency can help in training programs, setting benchmarks, and identifying areas for improvement. From this model The Hospital  can actually help identify which physicians are more efficient and thus may handle more patients or complex cases effectively

# **Story Telling**

So, I always have a habit To write some stories on the dataset , when I actually observed the dataset , I find their are two Unknown columns , It was for no use and  each one has their own special number that shows how good they are at treating patients. The lower the number, the better they are at their job and the less they cost for the same treatment. We also know where they work in big cities, if they're male or female, what kind of degree they have, and even which school they went to for medicine.

We can tell how experienced they are by the year they graduated from medical school. But there's this new amazing thing called the 'bump_feature.' It's like a ranking based on how efficient they are. Our data wizards also made some cool numbers that help us understand how doctors work, using info from Medicare about the patients they see and how risky their cases are.

This whole dataset tells a story about these doctors—how they work, where they studied, and how good they are at their jobs. And this new 'bump_feature'? It's like the secret sauce that makes our predictions even better!

OPTIONAL Question
"""